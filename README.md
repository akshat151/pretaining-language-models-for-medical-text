# pertaining-language-models-for-medical-text
This repository focuses on pretraining language models on the MeDAL dataset for medical text, utilizing multiple architectures to enhance performance for medical NLP tasks.

Paper [Link](https://arxiv.org/pdf/2012.13978)

Here, we will be focusing on pretraining the MeDAL dataset using an LSTM architecture.


